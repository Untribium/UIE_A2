{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import pickle\n",
    "import numpy.random as random\n",
    "\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(imgs, title=None):\n",
    "    # make sure input is a list\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    \n",
    "    plt.figure()\n",
    "        \n",
    "    for i in range(len(imgs)):\n",
    "        if(title is not None): \n",
    "            plt.suptitle(title)\n",
    "        plt.subplot(1, len(imgs), i+1)\n",
    "        plt.axis(\"off\")\n",
    "        # fix channels for rgb\n",
    "        if len(imgs[i].shape) > 2:\n",
    "            plt.imshow(imgs[i][:,:,[2,1,0]])\n",
    "        else:\n",
    "            plt.imshow(imgs[i])\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = 96\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images\n",
    "n_channels = 5\n",
    "\n",
    "# Number of classes, one class for each of the gestures.\n",
    "n_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(data_in):\n",
    "    \n",
    "    n = data_in.shape[0]\n",
    "    d = np.zeros(shape=n, dtype=[('x', np.uint8, (img_size, img_size, n_channels)), ('y', np.uint8, (20,))])\n",
    "\n",
    "    for i, (x, y) in enumerate(d):\n",
    "\n",
    "        x[...,:3] = data_in['rgb'][i]\n",
    "        x[..., 3] = data_in['dep'][i]\n",
    "        x[..., 4] = data_in['seg'][i]\n",
    "\n",
    "        y[data_in['lbl'][i]] = 1\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 77421\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "data_in = pickle.load(open(\"./data_pp/train_sa_new.pkl\", 'rb'))\n",
    "n_samples = data_in.shape[0]\n",
    "print('n_samples: {}'.format(n_samples))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data = transform_data(data_in)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subs in valid set: 25/200\n",
      "training set:\t 9754 samples\n",
      "validation set:\t67667 samples\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# separate data into training and validation set\n",
    "by_subjects = True\n",
    "\n",
    "# min number of samples in validation set\n",
    "valid_min = data_in.shape[0]//8\n",
    "\n",
    "if by_subjects:\n",
    "    subjects = np.array(list(set(data_in['sub'])))\n",
    "    random.shuffle(subjects)\n",
    "    counts = [(data_in['sub']==i).sum() for i in subjects]\n",
    "\n",
    "    index = 0\n",
    "    remaining = valid_min\n",
    "\n",
    "    while remaining > 0:\n",
    "        remaining -= counts[index]\n",
    "        index += 1\n",
    "        \n",
    "    print('subs in valid set: {}/{}'.format(index, subjects.shape[0]))\n",
    "    \n",
    "    train = data[np.in1d(data_in['sub'], subjects[:index])]\n",
    "    valid = data[np.in1d(data_in['sub'], subjects[index:])]\n",
    "    \n",
    "else:\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train = data[:valid_min]\n",
    "    valid = data[valid_min:]\n",
    "\n",
    "n_samples_train = train.shape[0]\n",
    "n_samples_valid = valid.shape[0]\n",
    "               \n",
    "print('training set:\\t{0: >5} samples'.format(n_samples_train))\n",
    "print('validation set:\\t{0: >5} samples'.format(n_samples_valid))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, n_channels], name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, 20], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pretty = pt.wrap(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pt.defaults_scope(activation_fn=tf.nn.relu, l2loss=1e-4):\n",
    "    y_pred, loss = x_pretty.\\\n",
    "        conv2d  (kernel=7, stride=1, depth= 32).\\\n",
    "        max_pool(kernel=2, stride=2).\\\n",
    "        conv2d  (kernel=5, stride=1, depth= 64).\\\n",
    "        max_pool(kernel=2, stride=2).\\\n",
    "        conv2d  (kernel=5, stride=1, depth=128).\\\n",
    "        max_pool(kernel=2, stride=2).\\\n",
    "        conv2d  (kernel=3, stride=1, depth=128).\\\n",
    "        max_pool(kernel=2, stride=2).\\\n",
    "        conv2d  (kernel=3, stride=1, depth= 64).\\\n",
    "        flatten().\\\n",
    "        dropout(keep_prob=0.5).\\\n",
    "        fully_connected(size=1024).\\\n",
    "        dropout(keep_prob=0.5).\\\n",
    "        fully_connected(size=128).\\\n",
    "        softmax_classifier(num_classes=n_classes, labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights_variable(layer_name):\n",
    "    # Retrieve an existing variable named 'weights' in the scope\n",
    "    # with the given layer_name.\n",
    "    # This is awkward because the TensorFlow function was\n",
    "    # really intended for another purpose.\n",
    "\n",
    "    with tf.variable_scope(layer_name, reuse=True):\n",
    "        variable = tf.get_variable('weights')\n",
    "\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_iterations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(n_iterations):\n",
    "    # ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations, total_iterations + n_iterations):\n",
    "\n",
    "        # draw a random batch of training samples\n",
    "        draw = random.choice(a=train, size=train_batch_size, replace=False)\n",
    "    \n",
    "        batch = {x: draw['x'], y_true: draw['y']}\n",
    "        \n",
    "        # run the optimizer on the batch\n",
    "        session.run(optimizer, feed_dict=batch)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print_valid_accuracy()\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            # calculate training accuracy\n",
    "            acc = session.run(accuracy, feed_dict=batch)\n",
    "\n",
    "            msg = \"iteration: {0:>6}, accuracy (training): {1:>6.1%}, learning rate: {2}\"\n",
    "            rate = learning_rate if type(learning_rate) == float else session.run(learning_rate)\n",
    "            \n",
    "            print(msg.format(i, acc, rate))\n",
    "\n",
    "    total_iterations += n_iterations\n",
    "    \n",
    "    print_valid_accuracy()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    print(\"elapsed: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred, correct):\n",
    "    # This function is called from print_valid_accuracy() below.\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # get misclassified images from the valid-set, prediction and correct value\n",
    "    images = valid['x'][incorrect][...,0]\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "    cls_true = valid['y'][incorrect].argmax(axis=1)\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[:9,...], cls_true=cls_true[:9,...], cls_pred=cls_pred[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the valid-set into smaller batches of this size.\n",
    "valid_batch_size = 256\n",
    "\n",
    "def print_valid_accuracy(show_example_errors=False):\n",
    "\n",
    "    # Allocate array for the prediction\n",
    "    cls_pred = np.zeros(shape=n_samples_valid, dtype=np.int)\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    while i < n_samples_valid:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + valid_batch_size, n_samples_valid)\n",
    "\n",
    "        # Get the images and labels from the valid-set between index i and j.\n",
    "        images = valid['x'][i:j]\n",
    "        labels = valid['y'][i:j]\n",
    "\n",
    "        # Calculate the predicted class\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict={x: images, y_true: labels})\n",
    "\n",
    "        # move indices to next batch\n",
    "        i = j\n",
    "\n",
    "    cls_true = valid['y'].argmax(axis=1)\n",
    "\n",
    "    correct = (cls_true == cls_pred)\n",
    "    correct_sum = correct.sum()\n",
    "    \n",
    "    acc = float(correct_sum) / n_samples_valid\n",
    "    \n",
    "    msg = \"accuracy (valid): {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, n_samples_valid))\n",
    "    \n",
    "    if show_example_errors:\n",
    "        print(\"example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (valid): 5.7% (3873 / 67667)\n",
      "iteration:      0, accuracy (training):   9.4%, learning rate: 0.0001\n",
      "iteration:    200, accuracy (training):   6.2%, learning rate: 0.0001\n",
      "iteration:    400, accuracy (training):   6.2%, learning rate: 0.0001\n",
      "iteration:    600, accuracy (training):   9.4%, learning rate: 0.0001\n",
      "iteration:    800, accuracy (training):  15.6%, learning rate: 0.0001\n",
      "accuracy (valid): 11.0% (7467 / 67667)\n",
      "iteration:   1000, accuracy (training):  14.1%, learning rate: 0.0001\n",
      "iteration:   1200, accuracy (training):  10.9%, learning rate: 0.0001\n",
      "iteration:   1400, accuracy (training):  12.5%, learning rate: 0.0001\n",
      "iteration:   1600, accuracy (training):  15.6%, learning rate: 0.0001\n",
      "iteration:   1800, accuracy (training):  18.8%, learning rate: 0.0001\n",
      "accuracy (valid): 14.6% (9888 / 67667)\n",
      "iteration:   2000, accuracy (training):  14.1%, learning rate: 0.0001\n",
      "iteration:   2200, accuracy (training):  15.6%, learning rate: 0.0001\n",
      "iteration:   2400, accuracy (training):  17.2%, learning rate: 0.0001\n",
      "iteration:   2600, accuracy (training):   7.8%, learning rate: 0.0001\n",
      "iteration:   2800, accuracy (training):  21.9%, learning rate: 0.0001\n",
      "accuracy (valid): 16.9% (11406 / 67667)\n",
      "iteration:   3000, accuracy (training):  21.9%, learning rate: 0.0001\n",
      "iteration:   3200, accuracy (training):  28.1%, learning rate: 0.0001\n",
      "iteration:   3400, accuracy (training):  48.4%, learning rate: 0.0001\n",
      "iteration:   3600, accuracy (training):  29.7%, learning rate: 0.0001\n",
      "iteration:   3800, accuracy (training):  28.1%, learning rate: 0.0001\n",
      "accuracy (valid): 20.3% (13720 / 67667)\n",
      "iteration:   4000, accuracy (training):  35.9%, learning rate: 0.0001\n",
      "iteration:   4200, accuracy (training):  35.9%, learning rate: 0.0001\n",
      "iteration:   4400, accuracy (training):  35.9%, learning rate: 0.0001\n",
      "iteration:   4600, accuracy (training):  34.4%, learning rate: 0.0001\n",
      "iteration:   4800, accuracy (training):  32.8%, learning rate: 0.0001\n",
      "accuracy (valid): 23.1% (15598 / 67667)\n",
      "elapsed: 0:09:54\n"
     ]
    }
   ],
   "source": [
    "optimize(n_iterations=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (valid): 23.0% (15544 / 67667)\n",
      "iteration:   5000, accuracy (training):  37.5%, learning rate: 0.0003\n",
      "iteration:   5200, accuracy (training):  40.6%, learning rate: 0.0003\n",
      "iteration:   5400, accuracy (training):  46.9%, learning rate: 0.0003\n",
      "iteration:   5600, accuracy (training):  46.9%, learning rate: 0.0003\n",
      "iteration:   5800, accuracy (training):  50.0%, learning rate: 0.0003\n",
      "accuracy (valid): 24.3% (16454 / 67667)\n",
      "elapsed: 0:02:23\n"
     ]
    }
   ],
   "source": [
    "optimize(n_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimize(n_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_valid_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_valid_accuracy(show_example_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add validation data to data for final training run\n",
    "train = np.concatenate((train, valid))\n",
    "n_samples_train = train.shape[0]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pickle.load(open(\"./data_pp/test_sa_new.pkl\", 'rb'))\n",
    "n_samples_test = len(data_test['dep'])\n",
    "print('n_samples: {}'.format(n_samples_test))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = transform_data(data_test)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "\n",
    "cls_pred = np.zeros(shape=n_samples_test, dtype=np.int)\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < n_samples_test:\n",
    "    # The ending index for the next batch is denoted j.\n",
    "    j = min(i + test_batch_size, n_samples_test)\n",
    "\n",
    "    # Get the images from the test-set between index i and j.\n",
    "    images = test['x'][i:j]\n",
    "\n",
    "    # Create a feed-dict with these images and labels.\n",
    "    batch = {x: images}\n",
    "\n",
    "    # Calculate the predicted class using TensorFlow.\n",
    "    cls_pred[i:j] = session.run(y_pred_cls, feed_dict=batch)\n",
    "\n",
    "    # Set the start-index for the next batch to the\n",
    "    # end-index of the current batch.\n",
    "    i = j\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.zeros((n_samples_test, 2))\n",
    "prediction[:, 0] = np.arange(n_samples_test)+1\n",
    "prediction[:, 1] = cls_pred\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prediction.csv', 'wb') as f:\n",
    "    f.write(b'ID,Prediction\\n')\n",
    "    np.savetxt(f, prediction, fmt='%i', delimiter=\",\")\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
